<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
   
	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-107715197-1', 'auto');
  ga('send', 'pageview');
</script>

  
  <meta charset="utf-8">
  <title>Visual Object Tracking using Adaptive Correlation Filters</title>

  <meta name="author" content="Nrupatunga" />
  <meta name="description" content="" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link rel="alternate" type="application/rss+xml" href="/atom.xml" />

  <link href="/vendor/css/bootstrap.min.css" rel="stylesheet">
  <link href="/vendor/css/font-awesome.min.css" rel="stylesheet">
  <link href="/vendor/css/academicons.min.css" rel="stylesheet">
  <link href="/vendor/pygments/default.css" rel="stylesheet">
  <link href="/css/bamos.css" rel="stylesheet">
  <link href="/css/sharingbuttons.css" rel="stylesheet">

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
	<div class="navbar navbar-default navbar-fixed-top">
		<div class="container">
			<div class="row">
				<div class="col-md-10 col-md-offset-1">
					<div class="navbar-header">
						  <a href="/" class="navbar-brand">
                  <div>
                      <img src="/images/me-circle.jpg" class="img-circle"></img>
		      Nrupatunga
                  </div>
              </a>
						<button class="navbar-toggle" type="button" data-toggle="collapse"
                    data-target="#navbar-main">
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
					</div>
					<div class="navbar-collapse collapse" id="navbar-main">
						<ul class="nav navbar-nav">
							<li>
								<a href="/">About</a>
							</li>
							<li>
								<a href="/blog/">Posts</a>
							</li>
							<li>
								<a href="/project/">Project</a>
							</li>
						</ul>
						<ul class="nav navbar-nav navbar-right" style="font-size: 1.5em">
							<li>
								<a
									href="../assets/nrupatunga-resume.pdf" target="_blank">
									
									<i class="fa fa-file-pdf-o"></i></a>
							</li>
							<li>
								<a href="http://github.com/Nrupatunga" target="_blank">
									<i class="fa fa-github"></i></a>
							</li>
							<li>
								<a href="https://in.linkedin.com/in/nrupatunga" target="_blank">
									<i class="fa fa-linkedin"></i></a>
							</li>
							
								
									
							
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>

  <br/>
<div class="container">
<div class="row">
<div class="col-md-10 col-md-offset-1">
  <h1>Visual Object Tracking using Adaptive Correlation Filters</h1>
<em>September 14, 2017</em>
<br>

<!-- From: http://sharingbuttons.io/ -->

<!-- Sharingbutton Twitter -->
<a class="resp-sharing-button__link"
	href="https://twitter.com/intent/tweet/?text=Visual Object Tracking using Adaptive Correlation Filters by @nrupatunga1987 &amp;url=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/" target="_blank" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
        <g>
            <path d="M23.444,4.834c-0.814,0.363-1.5,0.375-2.228,0.016c0.938-0.562,0.981-0.957,1.32-2.019c-0.878,0.521-1.851,0.9-2.886,1.104 C18.823,3.053,17.642,2.5,16.335,2.5c-2.51,0-4.544,2.036-4.544,4.544c0,0.356,0.04,0.703,0.117,1.036 C8.132,7.891,4.783,6.082,2.542,3.332C2.151,4.003,1.927,4.784,1.927,5.617c0,1.577,0.803,2.967,2.021,3.782 C3.203,9.375,2.503,9.171,1.891,8.831C1.89,8.85,1.89,8.868,1.89,8.888c0,2.202,1.566,4.038,3.646,4.456 c-0.666,0.181-1.368,0.209-2.053,0.079c0.579,1.804,2.257,3.118,4.245,3.155C5.783,18.102,3.372,18.737,1,18.459 C3.012,19.748,5.399,20.5,7.966,20.5c8.358,0,12.928-6.924,12.928-12.929c0-0.198-0.003-0.393-0.012-0.588 C21.769,6.343,22.835,5.746,23.444,4.834z"/>
        </g>
    </svg>
    </div>
  </div>
</a>

<!-- Sharingbutton Facebook -->
<a class="resp-sharing-button__link" href="https://facebook.com/sharer/sharer.php?u=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/" target="_blank" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
        <g>
            <path d="M18.768,7.465H14.5V5.56c0-0.896,0.594-1.105,1.012-1.105s2.988,0,2.988,0V0.513L14.171,0.5C10.244,0.5,9.5,3.438,9.5,5.32 v2.145h-3v4h3c0,5.212,0,12,0,12h5c0,0,0-6.85,0-12h3.851L18.768,7.465z"/>
        </g>
    </svg>
    </div>
  </div>
</a>

<!-- Sharingbutton Google+ -->
<a class="resp-sharing-button__link" href="https://plus.google.com/share?url=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/" target="_blank" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--google resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
        <g>
            <path d="M11.366,12.928c-0.729-0.516-1.393-1.273-1.404-1.505c0-0.425,0.038-0.627,0.988-1.368 c1.229-0.962,1.906-2.228,1.906-3.564c0-1.212-0.37-2.289-1.001-3.044h0.488c0.102,0,0.2-0.033,0.282-0.091l1.364-0.989 c0.169-0.121,0.24-0.338,0.176-0.536C14.102,1.635,13.918,1.5,13.709,1.5H7.608c-0.667,0-1.345,0.118-2.011,0.347 c-2.225,0.766-3.778,2.66-3.778,4.605c0,2.755,2.134,4.845,4.987,4.91c-0.056,0.22-0.084,0.434-0.084,0.645 c0,0.425,0.108,0.827,0.33,1.216c-0.026,0-0.051,0-0.079,0c-2.72,0-5.175,1.334-6.107,3.32C0.623,17.06,0.5,17.582,0.5,18.098 c0,0.501,0.129,0.984,0.382,1.438c0.585,1.046,1.843,1.861,3.544,2.289c0.877,0.223,1.82,0.335,2.8,0.335 c0.88,0,1.718-0.114,2.494-0.338c2.419-0.702,3.981-2.482,3.981-4.538C13.701,15.312,13.068,14.132,11.366,12.928z M3.66,17.443 c0-1.435,1.823-2.693,3.899-2.693h0.057c0.451,0.005,0.892,0.072,1.309,0.2c0.142,0.098,0.28,0.192,0.412,0.282 c0.962,0.656,1.597,1.088,1.774,1.783c0.041,0.175,0.063,0.35,0.063,0.519c0,1.787-1.333,2.693-3.961,2.693 C5.221,20.225,3.66,19.002,3.66,17.443z M5.551,3.89c0.324-0.371,0.75-0.566,1.227-0.566l0.055,0 c1.349,0.041,2.639,1.543,2.876,3.349c0.133,1.013-0.092,1.964-0.601,2.544C8.782,9.589,8.363,9.783,7.866,9.783H7.865H7.844 c-1.321-0.04-2.639-1.6-2.875-3.405C4.836,5.37,5.049,4.462,5.551,3.89z"/>
            <polygon points="23.5,9.5 20.5,9.5 20.5,6.5 18.5,6.5 18.5,9.5 15.5,9.5 15.5,11.5 18.5,11.5 18.5,14.5 20.5,14.5 20.5,11.5  23.5,11.5 	"/>
        </g>
    </svg>
    </div>
  </div>
</a>

<!-- Sharingbutton LinkedIn -->
<a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/&amp;title=Visual Object Tracking using Adaptive Correlation Filters&amp;summary=Visual Object Tracking using Adaptive Correlation Filters&amp;source=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/" target="_blank" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
        <g>
            <path d="M6.527,21.5h-5v-13h5V21.5z M4.018,6.5H3.988C2.478,6.5,1.5,5.318,1.5,4.019c0-1.329,1.008-2.412,2.547-2.412 c1.541,0,2.488,1.118,2.519,2.447C6.565,5.354,5.588,6.5,4.018,6.5z M15.527,12.5c-1.105,0-2,0.896-2,2v7h-5c0,0,0.059-12,0-13h5 v1.485c0,0,1.548-1.443,3.938-1.443c2.962,0,5.062,2.144,5.062,6.304V21.5h-5v-7C17.527,13.396,16.632,12.5,15.527,12.5z"/>
        </g>
    </svg>
    </div>
  </div>
</a>

<!-- Sharingbutton Reddit -->
<a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/" target="_blank" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
        <path d="M24,11.5c0-1.654-1.346-3-3-3c-0.964,0-1.863,0.476-2.422,1.241c-1.639-1.006-3.747-1.64-6.064-1.723 c0.064-1.11,0.4-3.049,1.508-3.686c0.72-0.414,1.733-0.249,3.01,0.478C17.189,6.317,18.452,7.5,20,7.5c1.654,0,3-1.346,3-3 s-1.346-3-3-3c-1.382,0-2.536,0.944-2.883,2.217C15.688,3,14.479,2.915,13.521,3.466c-1.642,0.945-1.951,3.477-2.008,4.551 C9.186,8.096,7.067,8.731,5.422,9.741C4.863,8.976,3.964,8.5,3,8.5c-1.654,0-3,1.346-3,3c0,1.319,0.836,2.443,2.047,2.844 C2.019,14.56,2,14.778,2,15c0,3.86,4.486,7,10,7s10-3.14,10-7c0-0.222-0.019-0.441-0.048-0.658C23.148,13.938,24,12.795,24,11.5z  M2.286,13.366C1.522,13.077,1,12.351,1,11.5c0-1.103,0.897-2,2-2c0.635,0,1.217,0.318,1.59,0.816 C3.488,11.17,2.683,12.211,2.286,13.366z M6,13.5c0-1.103,0.897-2,2-2s2,0.897,2,2c0,1.103-0.897,2-2,2S6,14.603,6,13.5z  M15.787,18.314c-1.063,0.612-2.407,0.949-3.787,0.949c-1.387,0-2.737-0.34-3.803-0.958c-0.239-0.139-0.321-0.444-0.182-0.683 c0.139-0.24,0.444-0.322,0.683-0.182c1.828,1.059,4.758,1.062,6.59,0.008c0.239-0.138,0.545-0.055,0.683,0.184 C16.108,17.871,16.026,18.177,15.787,18.314z M16,15.5c-1.103,0-2-0.897-2-2c0-1.103,0.897-2,2-2s2,0.897,2,2 C18,14.603,17.103,15.5,16,15.5z M21.713,13.365c-0.397-1.155-1.201-2.195-2.303-3.048C19.784,9.818,20.366,9.5,21,9.5 c1.103,0,2,0.897,2,2C23,12.335,22.468,13.073,21.713,13.365z"/>
    </svg>
    </div>
  </div>
</a>

<!-- Sharingbutton E-Mail -->
<a class="resp-sharing-button__link" href="mailto:?subject=Visual Object Tracking using Adaptive Correlation Filters&amp;body=http://nrupatunga.github.io/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/" target="_self" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24" xml:space="preserve">
        <path d="M22,4H2C0.897,4,0,4.897,0,6v12c0,1.103,0.897,2,2,2h20c1.103,0,2-0.897,2-2V6C24,4.897,23.103,4,22,4z M7.248,14.434 l-3.5,2C3.67,16.479,3.584,16.5,3.5,16.5c-0.174,0-0.342-0.09-0.435-0.252c-0.137-0.239-0.054-0.545,0.186-0.682l3.5-2 c0.24-0.137,0.545-0.054,0.682,0.186C7.571,13.992,7.488,14.297,7.248,14.434z M12,14.5c-0.094,0-0.189-0.026-0.271-0.08l-8.5-5.5 C2.997,8.77,2.93,8.46,3.081,8.229c0.15-0.23,0.459-0.298,0.691-0.147L12,13.405l8.229-5.324c0.232-0.15,0.542-0.084,0.691,0.147 c0.15,0.232,0.083,0.542-0.148,0.691l-8.5,5.5C12.189,14.474,12.095,14.5,12,14.5z M20.934,16.248 C20.842,16.41,20.673,16.5,20.5,16.5c-0.084,0-0.169-0.021-0.248-0.065l-3.5-2c-0.24-0.137-0.323-0.442-0.186-0.682 s0.443-0.322,0.682-0.186l3.5,2C20.988,15.703,21.071,16.009,20.934,16.248z"/>
    </svg>
    </div>
  </div>
</a>


<hr style="margin-top: 0;">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script src="/vendor/MathJax/MathJax.js?config=TeX-AMS_HTML"></script>

<p><strong>TIP</strong>: Please read the <a href="http://www.cs.colostate.edu/~draper/papers/bolme_cvpr10.pdf">paper</a> once and use the following notes to understand the algorithm better</p>

<p>The main idea of the paper is to model the appearance of the target
object, frame to frame by constantly updating the correlation filter
trained on example images and using the trained filter to update the
location of the target in current frame</p>

<p>We go through the code available in the
<strong><a href="https://github.com/opencv/opencv/blob/master/samples/python/mosse.py">link</a></strong>
and understand the implementation. Glancing through the code, I found
that good place to start is by understanding <strong><code class="highlighter-rouge">MOSSE</code></strong> class</p>

<hr />
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MOSSE</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">rect</span><span class="p">):</span>
        <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">rect</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">getOptimalDFTSize</span><span class="p">,</span> <span class="p">[</span><span class="n">x2</span><span class="o">-</span><span class="n">x1</span><span class="p">,</span> <span class="n">y2</span><span class="o">-</span><span class="n">y1</span><span class="p">])</span>
        <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="o">+</span><span class="n">x2</span><span class="o">-</span><span class="n">w</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">y1</span><span class="o">+</span><span class="n">y2</span><span class="o">-</span><span class="n">h</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x1</span><span class="o">+</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">w</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">y1</span><span class="o">+</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">h</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getRectSubPix</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre>
</div>

<p>Constructor <code class="highlighter-rouge">__init__</code>of <strong><code class="highlighter-rouge">MOSSE</code></strong> class takes <code class="highlighter-rouge">frame</code>,<code class="highlighter-rouge">rect</code> as inputs, where <code class="highlighter-rouge">frame</code>
is the input frame, <code class="highlighter-rouge">rect</code> is the initial bounding box input marked by
the user that encloses the  object of interest to track in rest of the frames.
The bounding box coordinates<code class="highlighter-rouge">x1, y1, x2, y2</code> are with respect to the frame.</p>

<hr />
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># map function: map(f, iterable) &lt;==&gt; [f(x) for x in iterable]</span>
<span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">getOptimalDFTSize</span><span class="p">,</span> <span class="p">[</span><span class="n">x2</span><span class="o">-</span><span class="n">x1</span><span class="p">,</span> <span class="n">y2</span><span class="o">-</span><span class="n">y1</span><span class="p">])</span>
<span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="o">+</span><span class="n">x2</span><span class="o">-</span><span class="n">w</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">y1</span><span class="o">+</span><span class="n">y2</span><span class="o">-</span><span class="n">h</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
</code></pre>
</div>

<p><code class="highlighter-rouge">cv2.getOptimalDFTSize(vecsize)</code><sup><a href="http://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#getoptimaldftsize">doc</a></sup>
returns the minimum number <code class="highlighter-rouge">N</code> that is greater than equal to <code class="highlighter-rouge">vecsize</code>,
so that the DFT of a vector of size <code class="highlighter-rouge">N</code> can be processed efficiently.</p>

<p>Here <code class="highlighter-rouge">w, h</code> are the updated width and height of the bounding box. Once
we find the new <code class="highlighter-rouge">w, h</code> we update the coordinates <code class="highlighter-rouge">x1, y1</code>. Rewrite
<code class="highlighter-rouge">(x1+x2-w)/2</code> as <code class="highlighter-rouge">(x2-w+x1)/2</code> to better understand the math this update</p>

<hr />

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x1</span><span class="o">+</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">w</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">y1</span><span class="o">+</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">h</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getRectSubPix</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre>
</div>

<p>We find the center of bounding box <code class="highlighter-rouge">x, y</code> using updated <code class="highlighter-rouge">x1, y1</code>, but these co-ordinates are with
respect to the <code class="highlighter-rouge">frame</code>. We extract the part of <code class="highlighter-rouge">frame</code> which is centered
at <code class="highlighter-rouge">x, y</code> with width <code class="highlighter-rouge">w</code> and height <code class="highlighter-rouge">h</code> using
<code class="highlighter-rouge">cv2.getRectSubPix</code><sup><a href="http://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#getrectsubpix">doc</a></sup></p>

<div class="image-wrapper">

  <p><img src="/assets/mosse/images/frame_bb.jpg" alt="" /></p>

  <p class="image-caption">Figure 1.1: Frame with bounding box marked</p>

</div>

<hr />

<p>The next step in the algorithm is to generate the groundtruth for each
input image <code class="highlighter-rouge">img</code>, and also preprocess the input.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">win</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">createHanningWindow</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_32F</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">g</span><span class="p">[</span><span class="n">h</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">w</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="n">g</span> <span class="o">/=</span> <span class="n">g</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
<span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dft</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DFT_COMPLEX_OUTPUT</span><span class="p">)</span>
</code></pre>
</div>

<hr />
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">win</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">createHanningWindow</span><span class="p">((</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CV_32F</span><span class="p">)</span>
</code></pre>
</div>
<p>Here <code class="highlighter-rouge">cv2.createHanningWindow</code><sup><a href="http://docs.opencv.org/2.4/modules/imgproc/doc/motion_analysis_and_object_tracking.html">doc</a></sup> 
generates the hanning windows coefficients of size <code class="highlighter-rouge">w, h</code>. The input
image signal is modulated with this function in order to reduce the edge
effects (high frequency).</p>

<table>
  <thead>
    <tr>
      <th>Hanning window</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/mosse/images/hanning.jpg" alt="" /></td>
    </tr>
  </tbody>
</table>

<p><sup> NOTE::<em>To understand the role of Hanning function, you need to understand
the concept of <strong>DFT leakage</strong>.  In short, when we deal with digital
signals, if the input signal does not contain frequencies which are
integer multiple of analysis frequencies, DFT leakage happens, This can
be avoided by modulating the input signal with different window
functions such as Hamming, Hanning and rectangular functions before
taking Fourier transform</em></sup></p>

<hr />

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">g</span><span class="p">[</span><span class="n">h</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">w</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="n">g</span> <span class="o">/=</span> <span class="n">g</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>
</code></pre>
</div>
<p>Basic idea of the algorithm is to train correlation filter <code class="highlighter-rouge">H*</code>, when
convolved with current input frame should give the new location of the
target. This filter is trained in Fourier domain because its
computationally efficient.</p>

<p>To train, we need input-groundtruth pair. For each <code class="highlighter-rouge">img</code>, groundtruth
<code class="highlighter-rouge">g</code> is Gaussian shaped peak centered on the target. Above code generates
normalized Gaussian with variance <code class="highlighter-rouge">2.0</code> as ground truth <code class="highlighter-rouge">g</code> for each
input image <code class="highlighter-rouge">img</code></p>

<table>
  <thead>
    <tr>
      <th>Ground truth (Gaussian peak)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/mosse/images/gt.jpg" alt="" /></td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dft</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DFT_COMPLEX_OUTPUT</span><span class="p">)</span>
</code></pre>
</div>
<p>Since we train the filter in Fourier domain, we take the Fourier
transform of Gaussian generated in the previous step.</p>

<hr />
<p>Once we generate the ground truth <code class="highlighter-rouge">g</code>, now we generate more training
examples lets call <code class="highlighter-rouge">num_images=128</code> in order to get good initial
estimate of <code class="highlighter-rouge">H</code>, which is done by random warping the
input image <code class="highlighter-rouge">img</code> using <code class="highlighter-rouge">cv2.warpAffine</code><sup><a href="http://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#getoptimaldftsize">doc</a></sup> function.</p>

<hr />
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">128</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">rnd_warp</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dft</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DFT_COMPLEX_OUTPUT</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">H1</span> <span class="o">+=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">H2</span> <span class="o">+=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span>     <span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">update_kernel</span><span class="p">()</span>
<span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
</code></pre>
</div>

<p><code class="highlighter-rouge">cv2.warpAffine</code> function needs <code class="highlighter-rouge">2 x 3</code> transformation matrix <code class="highlighter-rouge">T</code>, where top <code class="highlighter-rouge">T[:2, :2]</code> is <code class="highlighter-rouge">2 x 2</code>
rotation matrix<sup><a href="https://www.wikiwand.com/en/Rotation_matrix">doc</a></sup> and <code class="highlighter-rouge">T[:, 2]</code> is <code class="highlighter-rouge">2 x 1</code> is translation matrix.</p>

<hr />

<div class="language-python highlighter-rouge"><pre class="highlight"><code>    <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">rnd_warp</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">rnd_warp</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">coef</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">ang</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">coef</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">ang</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">ang</span><span class="p">)</span>
    <span class="n">T</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[</span><span class="n">c</span><span class="p">,</span><span class="o">-</span><span class="n">s</span><span class="p">],</span> <span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">c</span><span class="p">]]</span>
    <span class="n">T</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">coef</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">T</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cv2</span><span class="o">.</span><span class="n">warpAffine</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">borderMode</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BORDER_REFLECT</span><span class="p">)</span>
</code></pre>
</div>
<hr />

<p>The output of warping is shown below</p>

<table>
  <thead>
    <tr>
      <th>input image</th>
      <th>warped image</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/mosse/images/img_bb.jpg" alt="" /></td>
      <td><img src="/assets/mosse/images/warped.gif" alt="" /></td>
    </tr>
  </tbody>
</table>

<hr />

<p>Next step is to preprocess the warped image.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">+</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="p">(</span><span class="n">img</span><span class="o">-</span><span class="n">img</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">+</span><span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">img</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">win</span>
</code></pre>
</div>
<hr />

<p>During preprocessing, input is transformed using a <code class="highlighter-rouge">log</code> function which helps in low contrast
lighting situation, then we normalize the input  by subtracting the mean
and dividing by the standard deviation. The input is also modulated
using the hanning window as we discussed before to reduce the edge
effect. The output of the above code is shown below</p>

<table>
  <thead>
    <tr>
      <th>input image</th>
      <th>log transformed with reduced edge effect<sup>#</sup></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/mosse/images/img_bb.jpg" alt="" /></td>
      <td><img src="/assets/mosse/images/preprocess_with_han.gif" alt="" /></td>
    </tr>
  </tbody>
</table>

<p><sup># image values are normalized between <code class="highlighter-rouge">0-255</code> for display purpose </sup></p>

<hr />
<p>Next step includes implementing the equation
<img src="/assets/mosse/images/mosse_eqn.jpg" alt="" />, where <code class="highlighter-rouge">G</code> is Fourier transform of ground
truth <code class="highlighter-rouge">g</code>.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">H1</span> <span class="o">+=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">H2</span> <span class="o">+=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span>     <span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>

<p><code class="highlighter-rouge">F</code> is the Fourier transform of input <code class="highlighter-rouge">a</code> <sup>(in the code <code class="highlighter-rouge">F=A</code>)</sup>
<code class="highlighter-rouge">*</code> indicates the complex conjugate and <code class="highlighter-rouge">i</code> indicates the number of
image, which ranges from  <code class="highlighter-rouge">1 - 128</code> in our case</p>

<p><code class="highlighter-rouge">self.H1, self.H2</code> implements the numerator and denominator part respectively, using the 
<code class="highlighter-rouge">cv2.mulSpectrums</code><sup><a href="http://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html">doc</a></sup>.
<code class="highlighter-rouge">conjB=True</code> option conjugates the second input before mulitplication.</p>

<hr />

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">update_kernel</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">update_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">divSpec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

<span class="k">def</span> <span class="nf">divSpec</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
    <span class="n">Ar</span><span class="p">,</span> <span class="n">Ai</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">Br</span><span class="p">,</span> <span class="n">Bi</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">C</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ar</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="o">*</span><span class="n">Ai</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">Br</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="o">*</span><span class="n">Bi</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">C</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">C</span><span class="p">)])</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">C</span>
</code></pre>
</div>

<p>As next step, we get the initial estimation of <code class="highlighter-rouge">H*</code>, by calling
<code class="highlighter-rouge">self.update_kernel</code>. This function calls <code class="highlighter-rouge">divSpec</code> which performs
element wise division grouping real and imaginary part of the data</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">rate</span> <span class="o">=</span> <span class="mf">0.125</span><span class="p">):</span>
    <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getRectSubPix</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_resp</span><span class="p">,</span> <span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">psr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlate</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">good</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">psr</span> <span class="o">&gt;</span> <span class="mf">8.0</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">good</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">x</span><span class="o">+</span><span class="n">dx</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">dy</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getRectSubPix</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

    <span class="n">A</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dft</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DFT_COMPLEX_OUTPUT</span><span class="p">)</span>
    <span class="n">H1</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">H2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span>     <span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">H1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">rate</span><span class="p">)</span> <span class="o">+</span> <span class="n">H1</span> <span class="o">*</span> <span class="n">rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">H2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H2</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">rate</span><span class="p">)</span> <span class="o">+</span> <span class="n">H2</span> <span class="o">*</span> <span class="n">rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_kernel</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">correlate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">mulSpectrums</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">dft</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DFT_COMPLEX_OUTPUT</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">conjB</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">idft</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">DFT_SCALE</span> <span class="o">|</span> <span class="n">cv2</span><span class="o">.</span><span class="n">DFT_REAL_OUTPUT</span><span class="p">)</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">mval</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">mx</span><span class="p">,</span> <span class="n">my</span><span class="p">)</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">minMaxLoc</span><span class="p">(</span><span class="n">resp</span><span class="p">)</span>
    <span class="n">side_resp</span> <span class="o">=</span> <span class="n">resp</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">side_resp</span><span class="p">,</span> <span class="p">(</span><span class="n">mx</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="n">my</span><span class="o">-</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">mx</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="n">my</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">smean</span><span class="p">,</span> <span class="n">sstd</span> <span class="o">=</span> <span class="n">side_resp</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">side_resp</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">psr</span> <span class="o">=</span> <span class="p">(</span><span class="n">mval</span><span class="o">-</span><span class="n">smean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">sstd</span><span class="o">+</span><span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resp</span><span class="p">,</span> <span class="p">(</span><span class="n">mx</span><span class="o">-</span><span class="n">w</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">my</span><span class="o">-</span><span class="n">h</span><span class="o">//</span><span class="mi">2</span><span class="p">),</span> <span class="n">psr</span>
</code></pre>
</div>

<p>So far, we got the initial estimate of <code class="highlighter-rouge">H*</code>. With this <code class="highlighter-rouge">H*</code>, we update
the location of target in current frame. This is done by calling the
function <code class="highlighter-rouge">correlate</code>.</p>

<p><code class="highlighter-rouge">C = cv2.mulSpectrums(cv2.dft(img, flags=cv2.DFT_COMPLEX_OUTPUT), self.H, 0, conjB=True)</code> correlates the input image with filter. 
This is done in Fourier domain again. <code class="highlighter-rouge">resp = cv2.idft(C, flags=cv2.DFT_SCALE | cv2.DFT_REAL_OUTPUT)</code> takes
the <code class="highlighter-rouge">idft</code> of the <code class="highlighter-rouge">FFT</code> output to get the response in spatial domain.
Then, we find the maximum response and its location using <code class="highlighter-rouge">cv2.minMaxLoc</code><sup><a href="http://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html">doc</a></sup> in the line <code class="highlighter-rouge">_, mval, _, (mx, my) = cv2.minMaxLoc(resp)</code></p>

<p>We then calculate <strong>Peak-Sidelobe-Ratio (PSR)</strong>,  which is given by <code class="highlighter-rouge">PSR =
(mval - mean_side_lobe) / std_side_lobe</code>, where <code class="highlighter-rouge">mval</code> is maximum response.
The side lobe considered is <code class="highlighter-rouge">11x11</code> pixel around <code class="highlighter-rouge">(mx, my)</code>
<code class="highlighter-rouge">psr = (mval-smean) / (sstd+eps)</code>. <code class="highlighter-rouge">eps=1e-5</code> is used for numerical stability.
If <code class="highlighter-rouge">psr &lt;= 8.0</code>, then the object is considered to be occluded or
tracking has failed.</p>

<hr />

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">H1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">rate</span><span class="p">)</span> <span class="o">+</span> <span class="n">H1</span> <span class="o">*</span> <span class="n">rate</span>
<span class="bp">self</span><span class="o">.</span><span class="n">H2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">H2</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">rate</span><span class="p">)</span> <span class="o">+</span> <span class="n">H2</span> <span class="o">*</span> <span class="n">rate</span>
<span class="bp">self</span><span class="o">.</span><span class="n">update_kernel</span><span class="p">()</span>
</code></pre>
</div>

<p>Once we got the location <code class="highlighter-rouge">self.pos</code> of target for the current frame, we
update our estimate <code class="highlighter-rouge">H*</code> by calculating <code class="highlighter-rouge">self.H1</code> and <code class="highlighter-rouge">self.H2</code> and
updating the filter with learning rate of <code class="highlighter-rouge">0.125</code>. This continues for
each frame where we update the filter and the location of target hand in
hand.</p>

<p>Thats how tracking using correlation filter is done!. Hope you could
understand the algorithm better. Thank you for reading.</p>


</div>
</div>
</div>


  <script src="/js/sp.js"></script>
  <script src="/vendor/js/jquery.min.js"></script>
  <script src="/vendor/js/bootstrap.min.js"></script>
  <script src="/vendor/js/anchor.min.js"></script>
  <script src="/vendor/js/jquery.toc.js"></script>
  <script type="text/javascript">
   try {
       var snowplowTracker = Snowplow.getTrackerUrl('joule.isr.cs.cmu.edu:8081');
       snowplowTracker.enableLinkTracking();
       snowplowTracker.trackPageView();
   } catch (err) {}

   $("#toc").toc({
       'headings': 'h2,h3'
   });
   anchors.add('h2,h3');
  </script>

</body>

</html>
